{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine, text, MetaData, Table\n",
    "\n",
    "db_url = URL.create(\n",
    "    drivername=\"mysql+pymysql\",\n",
    "    username=\"teamx\",\n",
    "    password=\"#C!D123^-c12\",\n",
    "    host=\"112.125.88.107\",\n",
    "    port=5906,\n",
    "    database=\"TeamX_BIGAI\",\n",
    "    query={\"charset\": \"utf8mb4\"},\n",
    ")\n",
    "\n",
    "# db_url = URL.create(\n",
    "#     drivername=\"mysql+pymysql\",\n",
    "#     username=\"agentictrl\",\n",
    "#     password=\"`1qaz~!QAZ\",\n",
    "#     host=\"112.125.88.107\",\n",
    "#     port=5906,\n",
    "#     database=\"BIGAI\",\n",
    "#     query={\"charset\": \"utf8mb4\"},\n",
    "# )\n",
    "\n",
    "engine = create_engine(db_url, pool_pre_ping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metadata = MetaData()\n",
    "\n",
    "# åå°„å…¨éƒ¨è¡¨ç»“æ„\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "print(\"æ•°æ®åº“ BIGAI åŒ…å«ä»¥ä¸‹è¡¨ï¼š\")\n",
    "for tbl in metadata.sorted_tables:\n",
    "    print(f\"\\nğŸ—‚  è¡¨ï¼š{tbl.name}\")\n",
    "    for col in tbl.columns:\n",
    "        print(f\"   - {col.name} ({col.type}) {'PK' if col.primary_key else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id=\"results/test_for_train_pass8_gpu8_env77_20250817_1345\" # results/test_for_train_instruction\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"select * from(SELECT run_id, count(*) ct FROM `rollout_run` group by run_id) t order by ct desc\"))\n",
    "    rows = result.mappings().all()   # list[dict]ï¼Œä¾¿äºåç»­å¤„ç†\n",
    "print(f\"rollout_run å…± {len(rows)} è¡Œ\")\n",
    "# å¯é€‰ï¼šè½¬æˆ DataFrame æ–¹ä¾¿æŸ¥çœ‹\n",
    "import pandas as pd; pd.DataFrame(rows)[5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout_run å…± 7917 è¡Œ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reward</th>\n",
       "      <td>0.247063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reward\n",
       "reward  0.247063"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æŸ¥çœ‹run_idå·²é‡‡æ ·çš„æ•°æ®\n",
    "run_id=\"results/examples_linux_osworld_0912_4\" # results/test_for_train_instruction  results/pass@32_trainset90\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT * FROM `rollout_run` where run_id = 'results/singlehard_pass8_gpu2_env20_maxstep30_20250905_1616' order by create_at desc\"))\n",
    "    rows = result.mappings().all()   # list[dict]ï¼Œä¾¿äºåç»­å¤„ç†\n",
    "print(f\"rollout_run å…± {len(rows)} è¡Œ\")\n",
    "# å¯é€‰ï¼šè½¬æˆ DataFrame æ–¹ä¾¿æŸ¥çœ‹\n",
    "import pandas as pd; df=pd.DataFrame(rows)#[['trajectory_id','task_id','reward']].to_json(\"data_pass@32_trainset90_0826.json\", orient=\"records\", force_ascii=False, indent=4)\n",
    "# df.groupby(['task_id'], as_index=False).agg(success_rate=('reward', 'mean'),mean_step=('num_chunks', 'mean'),total=('num_chunks', 'size')).sort_values('task_id')\n",
    "df.agg(reward=('reward','mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ====== é…ç½® ======\n",
    "k = 5\n",
    "outdir = \"async_pass8_train15hard_lr1e-6_bz4_minibs64_downsample_stepwise_kl_maxstep30\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# åˆå¹¶è„šæœ¬è¾“å‡ºçš„ JSONï¼š{\"0\": [...task_ids], \"1\":[...], ...}\n",
    "STEP_TASK_JSON = \"trainset15hard_pass8_gpu2_env20_maxstep30_20250901_1835_merged_task_ids.json\"\n",
    "\n",
    "# ====== è¯»å– step_num -> task_idsï¼Œå¹¶æ„é€  task_id -> set(step_num) ======\n",
    "with open(STEP_TASK_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    step2tasks_raw = json.load(f)\n",
    "\n",
    "# keys è½¬ intï¼Œvalues è½¬ä¸º setï¼Œéšåå†å€’æ’\n",
    "step2tasks = {int(s): set(map(str, tids)) for s, tids in step2tasks_raw.items()}\n",
    "task2steps = defaultdict(set)\n",
    "for s, tids in step2tasks.items():\n",
    "    for t in tids:\n",
    "        task2steps[str(t)].add(s)\n",
    "\n",
    "# ====== 1) ä» model_version æå– step_numï¼›ä¸åŒ¹é…æ ¼å¼çš„ä¸€å¾‹è®°ä¸º 0ï¼ˆåˆå§‹æ¨¡å‹ï¼‰ ======\n",
    "pattern = re.compile(r'global_step_(\\d+)')\n",
    "\n",
    "df2 = df.copy()\n",
    "df2['step_num'] = (\n",
    "    df2['model_version'].astype(str)\n",
    "       .str.extract(pattern)      # æå–åˆ°çš„æ˜¯å­—ç¬¦ä¸²æˆ– NaN\n",
    "       .fillna('0')               # ä¸åŒ¹é…çš„è®¾ä¸º '0'\n",
    "       .astype(int)               # è½¬æˆæ•´æ•°\n",
    ")\n",
    "# ç¡®ä¿ task_id ä¸ºå­—ç¬¦ä¸²ï¼Œå’Œåˆå¹¶ JSON ä¸­ä¸€è‡´\n",
    "df2['task_id'] = df2['task_id'].astype(str)\n",
    "\n",
    "# ====== 2) æŒ‰ task_id + step_num åˆ†ç»„ï¼Œè®¡ç®—æˆåŠŸç‡ï¼ˆmean(reward)ï¼‰ ======\n",
    "df_task_step = (\n",
    "    df2.groupby(['task_id', 'step_num'], as_index=False)\n",
    "       .agg(success_rate=('reward', 'mean'))\n",
    ")\n",
    "\n",
    "# ====== 3) æ¯ k ä¸ª task_id ç”»ä¸€å¼ æŠ˜çº¿å›¾å¹¶ä¿å­˜ï¼›å‡ºç°çš„ step ç‚¹æ”¾å¤§ ======\n",
    "task_ids = sorted(df_task_step['task_id'].unique().tolist())\n",
    "\n",
    "# å¯è°ƒå‚æ•°ï¼šæ™®é€šç‚¹å¤§å°ã€æ”¾å¤§ç‚¹å¤§å°\n",
    "normal_ms = 36    # ç›¸å½“äº markersize ~ 6 ï¼ˆscatter çš„ s å•ä½æ˜¯ç‚¹^2ï¼‰\n",
    "highlight_ms = 160\n",
    "\n",
    "saved_files = []\n",
    "for i in range(0, len(task_ids), k):\n",
    "    chunk = task_ids[i:i+k]\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for tid in chunk:\n",
    "        g = (df_task_step[df_task_step['task_id'] == tid]\n",
    "             .sort_values('step_num'))\n",
    "\n",
    "        # å…ˆç”»æŠ˜çº¿ï¼ˆå¸¦å°ç‚¹ï¼‰\n",
    "        line, = plt.plot(\n",
    "            g['step_num'], g['success_rate'],\n",
    "            marker='o', linestyle='-',\n",
    "            label=str(tid), linewidth=1.6, markersize=4\n",
    "        )\n",
    "        color = line.get_color()\n",
    "\n",
    "        # éœ€è¦æ”¾å¤§çš„ stepï¼štask2steps ä¸­å‡ºç°çš„ step\n",
    "        steps_hi = task2steps.get(str(tid), set())\n",
    "        if steps_hi:\n",
    "            m = g['step_num'].isin(steps_hi)\n",
    "            # åŸºç¡€å°ç‚¹ï¼ˆä¸ plot çš„å°ç‚¹è§†è§‰ä¸Šç­‰ä»·ï¼‰å¯é€‰ï¼šå¦‚æœä½ æƒ³æ›´ç»†æ§åˆ¶ï¼Œå¯å…ˆå»æ‰ plot çš„ marker\n",
    "            # ç„¶åç”¨ä¸‹é¢ä¸¤æ®µåˆ†åˆ«ç”»æ™®é€šç‚¹ä¸é«˜äº®ç‚¹\n",
    "\n",
    "            # ï¼ˆå¯é€‰ï¼‰é‡ç”»æ™®é€šç‚¹ï¼Œä¿è¯æ™®é€šç‚¹ä¸é«˜äº®ç‚¹å¤§å°å¯¹æ¯”æ›´æ˜æ˜¾\n",
    "            # m_norm = ~m\n",
    "            # plt.scatter(g.loc[m_norm, 'step_num'], g.loc[m_norm, 'success_rate'],\n",
    "            #             s=normal_ms, c=[color], edgecolors='none', zorder=2)\n",
    "\n",
    "            # å åŠ é«˜äº®ï¼ˆæ”¾å¤§ï¼‰ç‚¹\n",
    "            plt.scatter(\n",
    "                g.loc[m, 'step_num'], g.loc[m, 'success_rate'],\n",
    "                s=highlight_ms, c=[color],\n",
    "                edgecolors='black', linewidths=0.8, zorder=3\n",
    "            )\n",
    "\n",
    "    plt.xlabel('step_num')\n",
    "    plt.ylabel('success rate (mean reward)')\n",
    "    plt.title(f'Success rate vs. step_num | tasks {i+1}-{i+len(chunk)}')\n",
    "    plt.legend(title='task_id', loc='best', frameon=True)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fname = os.path.join(outdir, f'success_rate_tasks_{i+1:03d}_{i+len(chunk):03d}.png')\n",
    "    plt.savefig(fname, dpi=150)\n",
    "    plt.close()\n",
    "    saved_files.append(fname)\n",
    "\n",
    "print(f\"Saved {len(saved_files)} figures to '{outdir}':\")\n",
    "for f in saved_files:\n",
    "    print(' -', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹run_idå·²é‡‡æ ·çš„æ•°æ®\n",
    "run_id=\"results/trainset15_pass16_gpu2_env20_maxstep15_20250829_1712\" # results/test_for_train_instruction  results/pass@32_trainset90\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT * FROM `rollout_run` where run_id = 'results/pass@32_trainset90_0826' order by create_at desc\"))\n",
    "    rows = result.mappings().all()   # list[dict]ï¼Œä¾¿äºåç»­å¤„ç†\n",
    "print(f\"rollout_run å…± {len(rows)} è¡Œ\")\n",
    "# å¯é€‰ï¼šè½¬æˆ DataFrame æ–¹ä¾¿æŸ¥çœ‹\n",
    "import pandas as pd; df=pd.DataFrame(rows)#[['trajectory_id','task_id','reward']].to_json(\"data_pass@32_trainset90_0826.json\", orient=\"records\", force_ascii=False, indent=4)\n",
    "df[(df['task_id']=='82279c77-8fc6-46f6-9622-3ba96f61b477')&(df['num_chunks']==14)]['trajectory_id'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task = (\n",
    "    df.groupby('task_id', as_index=False)\n",
    "      .agg(mean_reward=('reward', 'mean'),\n",
    "           mean_num_chunks=('num_chunks', 'mean'),\n",
    "           min_num_chunks=('num_chunks', 'min'))\n",
    ")\n",
    "df_task_filtered = df_task.query('0 < mean_reward < 0.3').query('25 < mean_num_chunks < 50')\n",
    "df_task_filtered.sort_values('mean_num_chunks', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT * FROM `rollout_run` where run_id='results/pass@32_trainset90_0826' order by create_at desc\"))\n",
    "    rows = result.mappings().all()   # list[dict]ï¼Œä¾¿äºåç»­å¤„ç†\n",
    "print(f\"rollout_run å…± {len(rows)} è¡Œ\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "g = (\n",
    "    df.groupby(\"task_id\", dropna=False)[\"reward\"]\n",
    "      .agg(cnt=\"size\", mean_reward=\"mean\")\n",
    ")\n",
    "valid_tasks = g.index[(g[\"cnt\"] == 32) & (g[\"mean_reward\"].gt(0.4) & g[\"mean_reward\"].lt(0.6))]\n",
    "filtered = df[df[\"task_id\"].isin(valid_tasks)].copy()\n",
    "\n",
    "# åªä¿ç•™éœ€è¦å¯¼å‡ºçš„åˆ—ï¼ˆå…ˆå¸¦ä¸ŠåŸå§‹ num_chunksï¼Œåé¢ä¼šè¦†ç›–ï¼‰\n",
    "cols = [\"trajectory_id\", \"task_id\", \"reward\", \"num_chunks\"]\n",
    "out = filtered[cols].copy()\n",
    "out[\"num_chunks\"] = np.ceil(out[\"num_chunks\"] / 5).astype(int)\n",
    "out[\"reward\"] = out[\"reward\"].astype(float)\n",
    "out = out.dropna(subset=[\"trajectory_id\", \"task_id\", \"reward\", \"num_chunks\"])\n",
    "out.to_json(\"trajectories.json\", orient=\"records\", force_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹run_idå·²ä¿å­˜çš„checkpoints\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT * FROM `checkpoint` where run_id = 'results/pass8_20250904_train15_pass8_gpu2_env20_vllm_logp_maxstep15_tesl_vllm_logp_test3' order by created_at\"))\n",
    "    rows = result.mappings().all()   # list[dict]ï¼Œä¾¿äºåç»­å¤„ç†\n",
    "print(f\"checkpoint å…± {len(rows)} è¡Œ\")\n",
    "# å¯é€‰ï¼šè½¬æˆ DataFrame æ–¹ä¾¿æŸ¥çœ‹\n",
    "print(rows[-1]['path'])\n",
    "import pandas as pd; pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ä»rollout_runä¸­åˆ é™¤æŸrun_idçš„æ•°æ®\n",
    "run_id=\"results/pass8_20250904_train15_pass8_gpu2_env20_vllm_logp_maxstep15_tesl_vllm_logp_test3\"\n",
    "with engine.begin() as conn:\n",
    "    will = conn.execute(\n",
    "        text(\"SELECT COUNT(*) FROM `checkpoint` WHERE `run_id` = :rid\"),\n",
    "        {\"rid\": run_id}\n",
    "    ).scalar_one()\n",
    "    print(f\"å°†åˆ é™¤ {will} è¡Œï¼ˆrun_id = {run_id}ï¼‰\")\n",
    "\n",
    "    res = conn.execute(\n",
    "        text(\"DELETE FROM `checkpoint` WHERE `run_id` = :rid\"),\n",
    "        {\"rid\": run_id}\n",
    "    )\n",
    "    print(f\"âœ… å·²åˆ é™¤ {res.rowcount} è¡Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ä»rollout_runä¸­åˆ é™¤æŸrun_idçš„æ•°æ®\n",
    "run_id=\"results/trainset15_pass8_gpu2_env20_maxstep30_20250901_1326\"\n",
    "with engine.begin() as conn:\n",
    "    will = conn.execute(\n",
    "        text(\"SELECT COUNT(*) FROM `rollout_run` WHERE `run_id` = :rid\"),\n",
    "        {\"rid\": run_id}\n",
    "    ).scalar_one()\n",
    "    print(f\"å°†åˆ é™¤ {will} è¡Œï¼ˆrun_id = {run_id}ï¼‰\")\n",
    "\n",
    "    res = conn.execute(\n",
    "        text(\"DELETE FROM `rollout_run` WHERE `run_id` = :rid\"),\n",
    "        {\"rid\": run_id}\n",
    "    )\n",
    "    print(f\"âœ… å·²åˆ é™¤ {res.rowcount} è¡Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id=\"results/test_for_train_pass8_gpu8_env77_20250817_1345\"\n",
    "with engine.connect() as conn:\n",
    "    cnt = conn.execute(\n",
    "        text(\"\"\"\n",
    "            SELECT COUNT(*) FROM `rollout_run`\n",
    "            WHERE `run_id` = :rid AND `used` != 0\n",
    "        \"\"\"),\n",
    "        {\"rid\": run_id},\n",
    "    ).scalar_one()\n",
    "print(f\"ç¡®è®¤ used!=0 çš„è¡Œæ•°ï¼š{cnt}\")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    res = conn.execute(\n",
    "        text(\"\"\"\n",
    "            UPDATE `rollout_run`\n",
    "            SET `used` = 0\n",
    "            WHERE `run_id` = :rid\n",
    "        \"\"\"),\n",
    "        {\"rid\": run_id},\n",
    "    )\n",
    "    print(f\"âœ… æ›´æ–°è¡Œæ•°: {res.rowcount}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ›´æ–°used = 0 æ•°æ®çš„model version\n",
    "run_id=\"results/pass@32_trainset90\"\n",
    "model_version = \"/workspace/computer-use/verl/checkpoints/verl_osworld_grpo/osworld_all_feasible_reward_script_grpo_k8s_0813_h8zdohoq/global_step_10/actor/huggingface\"\n",
    "model_version = \"/capacity/userdata/vcfenxd75jiv/shichenrui/ui_tars/ByteDance-Seed/UI-TARS-1.5\"\n",
    "with engine.connect() as conn:\n",
    "    cnt, sample = conn.execute(\n",
    "        text(\"\"\"\n",
    "            SELECT COUNT(*) AS cnt, MAX(`model_version`) AS sample_version\n",
    "            FROM `rollout_run`\n",
    "            WHERE `run_id` = :rid AND `used` = 0\n",
    "        \"\"\"),\n",
    "        {\"rid\": run_id},\n",
    "    ).one()\n",
    "print(f\"used=0 çš„å‰©ä½™è¡Œæ•°: {cnt}ï¼Œç¤ºä¾‹ç‰ˆæœ¬: {sample}\")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    res = conn.execute(\n",
    "        text(\"\"\"\n",
    "            UPDATE `rollout_run`\n",
    "            SET `model_version` = :mv\n",
    "            WHERE `run_id` = :rid AND `used` = 0\n",
    "        \"\"\"),\n",
    "        {\"mv\": model_version, \"rid\": run_id},\n",
    "    )\n",
    "    print(f\"âœ… æ›´æ–°è¡Œæ•°: {res.rowcount}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»Ÿè®¡run_id validation ç»“æœ\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# run_ids = [\"results/val_train150_uitars_maxstep50\", \n",
    "#            \"results/val_trainset90_px_08221633_step10\",\n",
    "#            \"results/val_trainset90_px_08221633_step20\", ]\n",
    "run_ids = [\"results/val_train154_maxstep30_tmp0_uitars\", \n",
    "           \"results/val_train150_uitars_maxstep50\",\n",
    "           #\"results/val_train154_maxstep30_tmp07_uitars\", \n",
    "           #\"results/val_train154_maxstep30_tmp07_20250829_1122_step36\",\n",
    "           \"results/val_train154_maxstep30_tmp0_20250829_1122_step36\",\n",
    "           #results/val_train154_maxstep30_tmp07_20250830_1230_step120\",\n",
    "           \"results/val_train154_maxstep30_tmp0_20250830_1230_step120\",\n",
    "           \"results/val_train154_maxstep30_tmp0_20250830_1230_step130\",\n",
    "           \"results/val_train154_maxstep100_tmp0_20250830_1230_step130\"]\n",
    "\n",
    "with open(\"../evaluation_examples/test_trainset_90.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    mapping = json.load(f)\n",
    "eval_task_ids = set()\n",
    "for _, lst in mapping.items():\n",
    "    eval_task_ids.update(lst)\n",
    "    \n",
    "placeholders = \", \".join([f\":id{i}\" for i in range(len(run_ids))]) or \":id0\"\n",
    "sql = text(f\"\"\"\n",
    "    SELECT reward, run_id, task_id\n",
    "    FROM rollout_run\n",
    "    WHERE run_id IN ({placeholders})\n",
    "\"\"\")\n",
    "params = {f\"id{i}\": rid for i, rid in enumerate(run_ids)} or {\"id0\": None}\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    df = pd.read_sql(sql, conn, params=params)\n",
    "\n",
    "def agg_by_run_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    x = df[\"reward\"].fillna(0)\n",
    "    reward_non_neg1 = np.where(x.eq(-1), 0, x).astype(float)\n",
    "\n",
    "    df_calc = pd.DataFrame({\n",
    "        \"run_id\": df[\"run_id\"].values,\n",
    "        \"reward_non_neg1\": reward_non_neg1\n",
    "    })\n",
    "\n",
    "    total_rows = df_calc.groupby(\"run_id\").size().rename(\"total_rows\")\n",
    "    total_score = df_calc.groupby(\"run_id\")[\"reward_non_neg1\"].sum().rename(\"total_score\")\n",
    "\n",
    "    result = (\n",
    "        pd.concat([total_rows, total_score], axis=1)\n",
    "        .assign(success_rate=lambda d: d[\"total_score\"] / d[\"total_rows\"])\n",
    "        .reset_index()\n",
    "        .sort_values(\"run_id\")\n",
    "    )\n",
    "    return result\n",
    "\n",
    "#df_reward0 = df[df[\"task_id\"].isin(task_reward0)]\n",
    "\n",
    "df_subset = df[df[\"task_id\"].isin(eval_task_ids)]\n",
    "result_subset = agg_by_run_id(df).rename(columns={\n",
    "    \"metric\": \"metric_subset\",\n",
    "    \"total_score\": \"total_score\",\n",
    "    \"total_rows\": \"total_rows_subset\",\n",
    "})\n",
    "\n",
    "result_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval_task_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_subset = agg_by_run_id(df_subset).rename(columns={\n",
    "    \"metric\": \"metric_subset\",\n",
    "    \"total_score\": \"total_score\",\n",
    "    \"total_rows\": \"total_rows_subset\",\n",
    "})\n",
    "result_subset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cua310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
